{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers={\n",
    "    'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) Apple WeKit /537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n",
    "} \n",
    "\n",
    "webpage = {}\n",
    "\n",
    "for i in range(1,6):\n",
    "    url = f'https://www.ambitionbox.com/list-of-companies?page={i}'\n",
    "    webpage[f'page{i}'] = requests.get(url, headers=headers).text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO FIND OUT NAMES OF THE COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page page1 --- 20\n",
      "TCS\n",
      "Accenture\n",
      "Wipro\n",
      "Cognizant\n",
      "Capgemini\n",
      "HDFC Bank\n",
      "Infosys\n",
      "ICICI Bank\n",
      "HCLTech\n",
      "Tech Mahindra\n",
      "Genpact\n",
      "Teleperformance\n",
      "Axis Bank\n",
      "Jio\n",
      "Concentrix Corporation\n",
      "Amazon\n",
      "iEnergizer\n",
      "Reliance Retail\n",
      "LTIMindtree\n",
      "IBM\n",
      "\n",
      "--- Page page2 --- 20\n",
      "HDB Financial Services\n",
      "Larsen & Toubro Limited\n",
      "Deloitte\n",
      "Kotak Mahindra Bank\n",
      "Reliance Industries\n",
      "Vodafone Idea\n",
      "Bharti Airtel\n",
      "BYJU'S\n",
      "WNS\n",
      "Tata Motors\n",
      "IDFC FIRST Bank\n",
      "Ernst & Young\n",
      "IndusInd Bank\n",
      "AU Small Finance Bank\n",
      "Bajaj Finserv\n",
      "Flipkart\n",
      "Muthoot FinCorp\n",
      "PwC\n",
      "Mahindra & Mahindra\n",
      "DXC Technology\n",
      "\n",
      "--- Page page3 --- 20\n",
      "Infosys BPM\n",
      "HDFC Life\n",
      "Bandhan Bank\n",
      "Conneqt Business Solutions\n",
      "Mphasis\n",
      "Yes Bank\n",
      "Tata Steel\n",
      "Quess\n",
      "Maruti Suzuki\n",
      "Startek\n",
      "Asian Paints\n",
      "UltraTech Cement\n",
      "Paytm\n",
      "Shriram Finance\n",
      "Bajaj Finance\n",
      "Equitas Small Finance Bank\n",
      "Sutherland Global Services\n",
      "EXL Service\n",
      "Cipla\n",
      "Ericsson\n",
      "\n",
      "--- Page page4 --- 20\n",
      "Ericsson\n",
      "Wells Fargo\n",
      "Dr. Reddy's\n",
      "Optum Global Solutions\n",
      "Delhivery\n",
      "ICICI Prudential Life Insurance\n",
      "JSW Steel\n",
      "JPMorgan Chase & Co.\n",
      "HGS\n",
      "Jana Small Finance Bank\n",
      "Ujjivan Small Finance Bank\n",
      "Sun Pharmaceutical Industries\n",
      "Hexaware Technologies\n",
      "Amazon Development Centre India\n",
      "Lupin\n",
      "Zydus Lifesciences\n",
      "L&T Construction\n",
      "Ekart Logistics\n",
      "Hindustan Unilever\n",
      "KPMG India\n",
      "\n",
      "--- Page page5 --- 20\n",
      "ITC\n",
      "Axis Max Life Insurance\n",
      "Megha Engineering & Infrastructures\n",
      "Tata Projects\n",
      "Coforge\n",
      "FIS\n",
      "L&T Technology Services\n",
      "Bajaj Life Insurance\n",
      "Cholamandalam Investment & Finance\n",
      "IIFL Finance\n",
      "Oracle\n",
      "Indian Army\n",
      "Omega Healthcare\n",
      "Muthoot Finance\n",
      "JLL\n",
      "eClerx\n",
      "HCL Group\n",
      "Piramal Finance\n",
      "Virtusa Consulting Services\n",
      "DMart\n"
     ]
    }
   ],
   "source": [
    "for page_no, html in webpage.items():\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    companies = soup.find_all('h2', class_='companyCardWrapper__companyName')\n",
    "    print(f\"\\n--- Page {page_no} ---\", len(companies))\n",
    "\n",
    "    for company in companies:\n",
    "        print(company.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Top Companies in India | AmbitionBox'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = BeautifulSoup(webpage['page1']).find_all('title')\n",
    "title[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO FIND OUT THE RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page page1 --- 20\n",
      "3.3\n",
      "3.7\n",
      "3.6\n",
      "3.6\n",
      "3.7\n",
      "3.8\n",
      "3.5\n",
      "4.0\n",
      "3.4\n",
      "3.4\n",
      "3.6\n",
      "3.8\n",
      "3.6\n",
      "4.4\n",
      "3.6\n",
      "3.9\n",
      "4.6\n",
      "3.9\n",
      "3.6\n",
      "3.9\n",
      "\n",
      "--- Page page2 --- 20\n",
      "3.9\n",
      "3.9\n",
      "3.7\n",
      "3.6\n",
      "4.0\n",
      "3.9\n",
      "3.8\n",
      "3.2\n",
      "3.3\n",
      "4.1\n",
      "3.9\n",
      "3.4\n",
      "3.4\n",
      "3.9\n",
      "3.9\n",
      "3.9\n",
      "4.5\n",
      "3.3\n",
      "4.0\n",
      "3.6\n",
      "\n",
      "--- Page page3 --- 20\n",
      "3.5\n",
      "3.9\n",
      "3.7\n",
      "3.6\n",
      "3.3\n",
      "3.7\n",
      "4.0\n",
      "3.8\n",
      "4.2\n",
      "3.1\n",
      "3.9\n",
      "4.1\n",
      "3.2\n",
      "3.9\n",
      "3.9\n",
      "4.4\n",
      "3.4\n",
      "3.6\n",
      "4.1\n",
      "4.0\n",
      "\n",
      "--- Page page4 --- 20\n",
      "4.0\n",
      "3.7\n",
      "4.0\n",
      "4.0\n",
      "3.8\n",
      "4.0\n",
      "3.9\n",
      "3.8\n",
      "3.7\n",
      "3.8\n",
      "4.0\n",
      "4.1\n",
      "3.4\n",
      "3.8\n",
      "4.1\n",
      "4.0\n",
      "4.0\n",
      "3.9\n",
      "4.2\n",
      "3.4\n",
      "\n",
      "--- Page page5 --- 20\n",
      "3.9\n",
      "4.0\n",
      "3.9\n",
      "4.2\n",
      "3.2\n",
      "3.8\n",
      "3.1\n",
      "3.9\n",
      "3.8\n",
      "4.0\n",
      "3.5\n",
      "4.7\n",
      "3.8\n",
      "3.7\n",
      "4.1\n",
      "3.1\n",
      "3.5\n",
      "4.2\n",
      "3.7\n",
      "3.9\n"
     ]
    }
   ],
   "source": [
    "for page_no, html in webpage.items():\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rating_div = soup.find_all(\"div\", class_=\"rating_text rating_text--md\")\n",
    "    print(f\"\\n--- Page {page_no} ---\", len(rating_div))\n",
    "\n",
    "    for rat in rating_div:\n",
    "        rating = rat.find(\"div\").text.strip()\n",
    "        print(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO FIND OUT THE NUMBER OF REVIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page page1 --- 20\n",
      "1.1L\n",
      "71.2k\n",
      "63.5k\n",
      "59.8k\n",
      "51.4k\n",
      "50.5k\n",
      "47.2k\n",
      "45.1k\n",
      "44.4k\n",
      "42.4k\n",
      "40.8k\n",
      "36.5k\n",
      "32.3k\n",
      "32.3k\n",
      "31.5k\n",
      "30.6k\n",
      "27.1k\n",
      "26.9k\n",
      "25.8k\n",
      "25.3k\n",
      "\n",
      "--- Page page2 --- 20\n",
      "25.1k\n",
      "23.2k\n",
      "22.3k\n",
      "21.9k\n",
      "19.8k\n",
      "17.5k\n",
      "16.8k\n",
      "16.5k\n",
      "14.8k\n",
      "14k\n",
      "14k\n",
      "13.9k\n",
      "13.8k\n",
      "13.8k\n",
      "12.6k\n",
      "12.6k\n",
      "12.1k\n",
      "12k\n",
      "11.8k\n",
      "11.8k\n",
      "\n",
      "--- Page page3 --- 20\n",
      "11.8k\n",
      "11.7k\n",
      "10.7k\n",
      "10.1k\n",
      "10k\n",
      "9.9k\n",
      "9.7k\n",
      "9.5k\n",
      "9.3k\n",
      "9.3k\n",
      "9.3k\n",
      "9.2k\n",
      "9.1k\n",
      "9k\n",
      "8.9k\n",
      "8.7k\n",
      "8.7k\n",
      "8.4k\n",
      "8.4k\n",
      "8.3k\n",
      "\n",
      "--- Page page4 --- 20\n",
      "8.3k\n",
      "8.2k\n",
      "8.1k\n",
      "7.8k\n",
      "7.6k\n",
      "7.6k\n",
      "7.6k\n",
      "7.6k\n",
      "7.6k\n",
      "7.5k\n",
      "7.5k\n",
      "7.5k\n",
      "7.4k\n",
      "7.4k\n",
      "7.2k\n",
      "7.2k\n",
      "7.2k\n",
      "7.2k\n",
      "7.1k\n",
      "7k\n",
      "\n",
      "--- Page page5 --- 20\n",
      "7k\n",
      "6.9k\n",
      "6.8k\n",
      "6.7k\n",
      "6.5k\n",
      "6.5k\n",
      "6.4k\n",
      "6.4k\n",
      "6.4k\n",
      "6.3k\n",
      "6.2k\n",
      "6.2k\n",
      "6.2k\n",
      "6.2k\n",
      "6.2k\n",
      "6.1k\n",
      "6.1k\n",
      "6k\n",
      "6k\n",
      "5.9k\n"
     ]
    }
   ],
   "source": [
    "for page_no, html in webpage.items():\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    rating_counts = soup.find_all(\"span\", class_=\"companyCardWrapper__companyRatingCount\")\n",
    "    print(f\"\\n--- Page {page_no} ---\", len(rating_counts))\n",
    "\n",
    "    for count in rating_counts:\n",
    "        text = count.text.strip()\n",
    "        rating_count = text[1:-1]\n",
    "        print(rating_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = BeautifulSoup(webpage['page1'], 'html.parser')\n",
    "rating_div = test.find_all('div', class_='rating_text')\n",
    "len(rating_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONSIDERING THE WHOLE CONTAINER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = []\n",
    "ratings = []\n",
    "reviews = []\n",
    "sectors = []\n",
    "locations = []\n",
    "highly_rated_for = []\n",
    "critically_rated_for = []\n",
    "\n",
    "for i in range(1, 501):\n",
    "    url = f'https://www.ambitionbox.com/list-of-companies?page={i}'\n",
    "    headers={\n",
    "        'User-Agent':'Mozilla/5.0 (Windows NT 6.3; Win 64 ; x64) AppleWebKit/537.36(KHTML , like Gecko) Chrome/80.0.3987.162 Safari/537.36'\n",
    "    } \n",
    "    page = requests.get(url, headers=headers).text\n",
    "    time.sleep(1) # added time delay to avoid blocking\n",
    "\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    company = soup.find_all('div', class_='companyCardWrapper')\n",
    "\n",
    "    for container in company:\n",
    "        # company name\n",
    "        name.append(container.find('h2', class_='companyCardWrapper__companyName').text.strip())\n",
    "\n",
    "        #rating\n",
    "        rating_div = container.find(\"div\", class_=\"rating_text rating_text--md\")\n",
    "        rating = rating_div.find('div').text.strip()\n",
    "        ratings.append(rating)\n",
    "\n",
    "        #reviews\n",
    "        reviews.append(container.find('span', class_='companyCardWrapper__ActionCount').text.strip())\n",
    "\n",
    "        #sector and location\n",
    "        company_profile = container.find('span', class_='companyCardWrapper__interLinking').text.strip()\n",
    "        company_parts = company_profile.split('|')\n",
    "\n",
    "        industry = np.nan\n",
    "        location = np.nan\n",
    "\n",
    "        if len(company_parts) == 2:\n",
    "            industry = company_parts[0].strip()\n",
    "            location = company_parts[1].strip()\n",
    "\n",
    "        elif len(company_parts) == 1:\n",
    "            text = company_parts[0].strip()\n",
    "\n",
    "            # If it contains words like Bangalore, Mumbai, Gurgaon â†’ it's location\n",
    "            if any(city in text.lower() for city in [\"bangalore\", \"mumbai\", \"delhi\", \"gurgaon\", \"noida\", \"hyderabad\", \"chennai\", \"pune\"]):\n",
    "                location = text\n",
    "            else:\n",
    "                industry = text\n",
    "\n",
    "        sectors.append(industry)\n",
    "        locations.append(location)\n",
    "\n",
    "        # highly and critically rated aspects\n",
    "        high_value = np.nan\n",
    "        critical_value = np.nan\n",
    "\n",
    "        rating_blocks = container.find_all('div', class_='companyCardWrapper__ratingHeader')\n",
    "\n",
    "        for block in rating_blocks:\n",
    "            heading = block.find('span').text.strip().lower()\n",
    "            value = block.find_next_sibling('span', class_='companyCardWrapper__ratingValues').text.strip()\n",
    "\n",
    "            if 'highly' in heading:\n",
    "                high_value = value\n",
    "            elif 'critical' in heading:\n",
    "                critical_value = value\n",
    "        \n",
    "        highly_rated_for.append(high_value)\n",
    "        critically_rated_for.append(critical_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = []\n",
    "# ratings = []\n",
    "# reviews = []\n",
    "# sectors = []\n",
    "# locations = []\n",
    "# highly_rated_for = []\n",
    "# critically_rated_for = []\n",
    "\n",
    "# for container in company:\n",
    "#     name.append(container.find('h2', class_='companyCardWrapper__companyName').text.strip())\n",
    "\n",
    "#     rating_div = container.find(\"div\", class_=\"rating_text rating_text--md\")\n",
    "#     rating = rating_div.find('div').text.strip()\n",
    "#     ratings.append(rating)\n",
    "\n",
    "#     reviews.append(container.find('span', class_='companyCardWrapper__ActionCount').text.strip())\n",
    "\n",
    "#     company_profile = container.find('span', class_='companyCardWrapper__interLinking').text.strip()\n",
    "#     company_parts = company_profile.split('|')\n",
    "\n",
    "#     sector = company_parts[0].strip()\n",
    "#     location = company_parts[1].strip()\n",
    "\n",
    "#     sectors.append(sector)\n",
    "#     locations.append(location)\n",
    "\n",
    "#     high_value = np.nan\n",
    "#     critical_value = np.nan\n",
    "\n",
    "#     rating_blocks = container.find_all('div', class_='companyCardWrapper__ratingHeader')\n",
    "\n",
    "#     for block in rating_blocks:\n",
    "#         heading = block.find('span').text.strip().lower()\n",
    "#         value = block.find_next_sibling('span', class_='companyCardWrapper__ratingValues').text.strip()\n",
    "\n",
    "#         if 'highly' in heading:\n",
    "#             high_value = value\n",
    "#         elif 'critical' in heading:\n",
    "#             critical_value = value\n",
    "    \n",
    "#     highly_rated_for.append(high_value)\n",
    "#     critically_rated_for.append(critical_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = {\n",
    "    'company_name': name,\n",
    "    'ratings':ratings,\n",
    "    'reviews':reviews,\n",
    "    'Industry':sectors,\n",
    "    'locations':locations,\n",
    "    'highly_rated_aspects':highly_rated_for,\n",
    "    'critically_rated_aspects':critically_rated_for\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dataframe = pd.DataFrame(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "      <th>Industry</th>\n",
       "      <th>locations</th>\n",
       "      <th>highly_rated_aspects</th>\n",
       "      <th>critically_rated_aspects</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TCS</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.1L</td>\n",
       "      <td>IT Services &amp; Consulting</td>\n",
       "      <td>Bangalore / Bengaluru +439 other locations</td>\n",
       "      <td>Job Security</td>\n",
       "      <td>Promotions / Appraisal, Salary &amp; Benefits, Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Accenture</td>\n",
       "      <td>3.7</td>\n",
       "      <td>71.2k</td>\n",
       "      <td>IT Services &amp; Consulting</td>\n",
       "      <td>Bangalore / Bengaluru +255 other locations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotions / Appraisal, Salary &amp; Benefits, Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wipro</td>\n",
       "      <td>3.6</td>\n",
       "      <td>63.5k</td>\n",
       "      <td>IT Services &amp; Consulting</td>\n",
       "      <td>Hyderabad / Secunderabad +370 other locations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotions / Appraisal, Salary &amp; Benefits, Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3.6</td>\n",
       "      <td>59.8k</td>\n",
       "      <td>IT Services &amp; Consulting</td>\n",
       "      <td>Hyderabad / Secunderabad +229 other locations</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Promotions / Appraisal, Salary &amp; Benefits, Wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Capgemini</td>\n",
       "      <td>3.7</td>\n",
       "      <td>51.4k</td>\n",
       "      <td>IT Services &amp; Consulting</td>\n",
       "      <td>Bangalore / Bengaluru +183 other locations</td>\n",
       "      <td>Work Life Balance, Job Security</td>\n",
       "      <td>Promotions / Appraisal, Salary &amp; Benefits</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name ratings reviews                  Industry  \\\n",
       "0          TCS     3.3    1.1L  IT Services & Consulting   \n",
       "1    Accenture     3.7   71.2k  IT Services & Consulting   \n",
       "2        Wipro     3.6   63.5k  IT Services & Consulting   \n",
       "3    Cognizant     3.6   59.8k  IT Services & Consulting   \n",
       "4    Capgemini     3.7   51.4k  IT Services & Consulting   \n",
       "\n",
       "                                       locations  \\\n",
       "0     Bangalore / Bengaluru +439 other locations   \n",
       "1     Bangalore / Bengaluru +255 other locations   \n",
       "2  Hyderabad / Secunderabad +370 other locations   \n",
       "3  Hyderabad / Secunderabad +229 other locations   \n",
       "4     Bangalore / Bengaluru +183 other locations   \n",
       "\n",
       "              highly_rated_aspects  \\\n",
       "0                     Job Security   \n",
       "1                              NaN   \n",
       "2                              NaN   \n",
       "3                              NaN   \n",
       "4  Work Life Balance, Job Security   \n",
       "\n",
       "                            critically_rated_aspects  \n",
       "0  Promotions / Appraisal, Salary & Benefits, Wor...  \n",
       "1  Promotions / Appraisal, Salary & Benefits, Wor...  \n",
       "2  Promotions / Appraisal, Salary & Benefits, Wor...  \n",
       "3  Promotions / Appraisal, Salary & Benefits, Wor...  \n",
       "4          Promotions / Appraisal, Salary & Benefits  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 7)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_dataframe.to_csv('ambitionbox_companies_2026_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
